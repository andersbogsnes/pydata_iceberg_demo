{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ce947-632e-4dd2-9bb4-15a75f4a5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import BooleanType, DoubleType, LongType, StringType, TimestampType, NestedField, IntegerType\n",
    "from pyiceberg.transforms import MonthTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bc7ac-62c1-4b7b-933c-02c896269bae",
   "metadata": {},
   "source": [
    "First we need to connect to our Iceberg catalogue - since currently the client is doing the reading and writing, we also set the access credentials. This can also be done in a `.pyiceberg.yaml` file.\n",
    "\n",
    "Note that normally, the REST catalogue can handle all S3 auth, sending a signed S3 url to the client to upload - but that would require additional auth setup, so we pass the client credentials directly here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476e50b-fd1a-46f8-b5fe-8ec00703f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog(\"nessie\", **{\"uri\": \"http://nessie:19120/iceberg\", \"s3.access-key-id\": \"minio\", \"s3.secret-access-key\": \"minio1234\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f79c2b-11f7-4494-b43e-0d6e32b360ab",
   "metadata": {},
   "source": [
    "Iceberg metadata is organized in `namespaces` which would be the equivalent of a schema in a database.\n",
    "\n",
    "Here we name our catalog `steam` to represent data that comes from Steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124368e-cef5-4d7e-93f3-b968963a28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.create_namespace_if_not_exists(\"steam\")\n",
    "catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4565f0-9986-43e5-bd46-368a52385cb9",
   "metadata": {},
   "source": [
    "We can define a schema using pyiceberg. Note that each field needs a unique id within the schema, as one of the ways that Iceberg can handle schema migrations is by referencing each field by position rather than by name, but we'll see an example of that later.\n",
    "\n",
    "We will create a table containing a small subset for demonstration purposes, as it's a bit tedious to write out the whole schema by hand ðŸ˜…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cc1c6-fe6c-444c-b3cf-7178e3de4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "    NestedField(id=1, name='recommendationid', type=LongType()),\n",
    "    NestedField(id=2, name='language', type=StringType()),\n",
    "    NestedField(id=3, name='timestamp_created', type=TimestampType()),\n",
    "    NestedField(id=4, name='voted_up', type=BooleanType()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bcfe87-35c5-4984-a68f-4366e6726bd8",
   "metadata": {},
   "source": [
    "Now we're ready to create the table, by passing the schema to the catalog. It will take care of writing a metadata file in the object storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb3977-16fa-4d2a-8fc4-fed3ad7b1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.create_table_if_not_exists(\"steam.languages\", schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f0034f-14c9-4753-a67a-a263272ed757",
   "metadata": {},
   "source": [
    "Let's insert some data into the table. Pyiceberg supports Arrow out of the box, so we use Polars to read data in and turn it into Arrow format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df51da-92c1-4ef7-88cc-6022be92985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"data/10.csv\").select(pl.col('recommendationid'), \n",
    "                                       pl.col('language'), \n",
    "                                      pl.from_epoch(pl.col('timestamp_created')),\n",
    "                                      pl.col('voted_up').cast(pl.Boolean)\n",
    "                                      ).filter(pl.col('recommendationid').is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815882b-1108-4805-9be8-123c2beaf9b1",
   "metadata": {},
   "source": [
    "Now we can `overwrite` or `append` this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed7cb7-f9f7-4e11-bb9b-0db33d7c904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append(df.to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af93e46-482a-4d00-858b-d74f6d151529",
   "metadata": {},
   "source": [
    "Now that there's data in the table, we can scan the Iceberg table, filtering out the records we don't need. Pyiceberg will use the metadata stored in Iceberg to quickly locate the correct files, and only read the necessary parts of those files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ceaa2b-d995-4fd0-8cee-02deddd12236",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = table.scan().to_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02bd2c-03d4-4b02-b9f3-53155b1d7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total rows in table: {table.scan().to_arrow().shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b79bd-58b2-424e-9669-96306293de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pl.from_arrow(table.scan(selected_fields=['language', 'voted_up'], \n",
    "                                #Alternatively use expressions -> EqualTo('language', 'english')\n",
    "                                row_filter=\"language == 'english'\"\n",
    "                                 ).to_arrow()\n",
    "                      )\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93355186-283e-43e6-8884-20dc4ac5b767",
   "metadata": {},
   "source": [
    "One problem we have now, is that we don't actually have the game id in the table - that would be pretty useful. If we just try to insert data with the added column, that wouldn't work as the Iceberg schema doesn't contain the `game_id` column and will error to protect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcfdb1-fd37-4fd9-98ab-4481d33c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game = df.with_columns(game_id=pl.lit(\"10\"))\n",
    "table.overwrite(df_game.to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f3c33-de3f-49da-b204-60d959ff2b83",
   "metadata": {},
   "source": [
    "Luckily in Iceberg, we can update the schema without having to rewrite all the physical files, much like in a traditional RDBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184212d6-4073-4eb0-bfd4-71299010b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "with table.update_schema() as update:\n",
    "    update.add_column('game_id', StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d7fee-69af-4c68-b77e-b5918225fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af63725-fc28-4e29-b91d-cc4612375e34",
   "metadata": {},
   "source": [
    "PyIceberg makes sure to give it a valid ID and puts it at the end of the schema. We can move the fields around as we want by updating the metadata, Iceberg keeps track of the corresponding data positions without having to rewrite the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6cb3f-e370-469b-a31f-c49676703cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with table.update_schema() as update:\n",
    "    update.move_first('game_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b566f6-bd3c-4d6b-b9dc-b0fc90ba5cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84eae6-b6a2-4363-b13d-9f8188d7b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.overwrite(df_game.to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11a5df-8cb1-4ec8-9c47-bab6c6594b28",
   "metadata": {},
   "source": [
    "`game_id` should now be the first column of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180392ca-7dca-4ba6-be15-a295a83a90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.from_arrow(table.scan().to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7efea0-619e-47f2-8abc-3f973629acee",
   "metadata": {},
   "source": [
    "Now we're ready to insert some more data using `.append`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff887d-1817-4e7c-bac0-ce3d9c3186ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "civ6_df = pl.read_csv('data/289070.csv').select(\n",
    "    pl.lit('289070').alias('game_id'),\n",
    "    pl.col('recommendationid'),\n",
    "    pl.col('language'),\n",
    "    pl.from_epoch(pl.col('timestamp_created')),\n",
    "    pl.col('voted_up').cast(pl.Boolean)\n",
    ")\n",
    "civ6_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8282d9-3095-45d4-a0d4-a54cb4b3eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append(civ6_df.to_arrow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a038937-396d-4d17-af08-a6cd492055d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = table.scan().to_arrow()\n",
    "print(f\"Current rows: {t.shape[0]:,}\")\n",
    "pl.from_arrow(t).select(pl.col('game_id').unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14cbce7-75d2-4bc9-a29c-f25c5fd16c88",
   "metadata": {},
   "source": [
    "Let's add some more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed8780-410f-4cec-bd41-0939b649dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs2 = pl.read_csv('data/730.csv').select(\n",
    "    pl.lit('730').alias('game_id'),\n",
    "    pl.col('recommendationid'),\n",
    "    pl.col('language'),\n",
    "    pl.from_epoch(pl.col('timestamp_created')),\n",
    "    pl.col('voted_up').cast(pl.Boolean)\n",
    ")\n",
    "cs2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dc612-1c46-48ef-ba36-bcf2f97ac93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append(cs2.to_arrow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1514bc8-5a97-44ec-bbfb-75948ae116d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The table has {table.scan().to_arrow().num_rows:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56408eab-ac4a-4f99-a7b1-77545924e7a7",
   "metadata": {},
   "source": [
    "What if I find out that the end-users are mainly trying to analyze the upvotes over time? The Dashboard has been built, but it's not performing as they want. Partitioning might be the answer, but with Iceberg, we don't have to physically rewrite all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a75aa5-a05e-4bf8-8198-781f29caf91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with table.update_spec() as update:\n",
    "    update.add_field(\"timestamp_created\", MonthTransform(), 'month_created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc8742-6eec-42ca-b43a-eb6f9dda9e7e",
   "metadata": {},
   "source": [
    "Nothing has happened yet, the Iceberg metada has been updated with the partition - no need to rewrite all the files. \n",
    "\n",
    "If we insert new data, it will be partitioned by our new partitioning schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0c632-02be-492f-bfe0-88f2a6d0987c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pubg = pl.read_csv('data/578080.csv').select(\n",
    "    pl.lit('578080').alias('game_id'),\n",
    "    pl.col('recommendationid'),\n",
    "    pl.col('language'),\n",
    "    pl.from_epoch(pl.col('timestamp_created')),\n",
    "    pl.col('voted_up').cast(pl.Boolean)\n",
    ")\n",
    "pubg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82b6b8-09de-45e3-baf6-c14d66a12ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.append(pubg.to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523c291-f157-4a15-a60a-407a3778cd0b",
   "metadata": {},
   "source": [
    "Iceberg knows the partitioning scheme for each of the manifest lists and will generate a plan for each file independently\n",
    "\n",
    "![Partition Spec Evolution](images/partition_spec_evolution.png)\n",
    "\n",
    "> https://iceberg.apache.org/docs/latest/evolution/#partition-evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc68f97-3dc5-486e-98f5-856452789a9a",
   "metadata": {},
   "source": [
    "# Write-Audit-Publish with Git-for-data branches\n",
    "\n",
    "Nessie provides the ability to perform a Write-Audit-Publish pattern, through git branching of data. Using the mechanisms of Iceberg, Nessie can keep track of the different branches of data, allowing us git-like semantics for working with data. Pyiceberg doesn't yet support this Nessie-specific syntax, so we're going to switch to another project, Dremio. We could also have chose a number of other query engines such as Apache Spark, or Trino/Presto as well.\n",
    "\n",
    "A nice thing about Dremio is that since it's Arrow-backed internally, they also expose FlightSQL endpoints, letting us use ADBC as a generic DB client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a311a2-4bd7-4df5-92ad-e79eae2f4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adbc_driver_flightsql.dbapi import connect\n",
    "from adbc_driver_flightsql import DatabaseOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea808a-0a55-4a1f-8c0c-824aa69fe6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(\"grpc+tcp://dremio:32010\", \n",
    "               db_kwargs={\"username\": \"dremio\", \n",
    "                          \"password\": \"dremio123\", \n",
    "                          DatabaseOptions.WITH_COOKIE_MIDDLEWARE.value: \"true\"}, \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26179ff-8881-442e-87ab-a16d989969e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"SELECT 1\")\n",
    "    print(c.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ab28c-1d07-4748-bb4d-a79fe56bf753",
   "metadata": {},
   "source": [
    "Dremio has been pre-configured to talk to Nessie, and since Iceberg is client-agnostic, Dremio can read all the Iceberg tables registered in the Nessie catalogue. We're taking advantage of the Arrow-based nature of Dremio, Polars and ADBC to be able to interact directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19d243-96f6-463c-8aff-60bd8e000551",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT * FROM Nessie.steam.languages LIMIT 10\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b8a54-f46d-4c73-944e-323c69a455bc",
   "metadata": {},
   "source": [
    "Where before, `pyiceberg` let us filter the data, a query engine like Dremio can do SQL to do all the analytics we're used to from a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547be499-5909-4d04-ad4d-b40051cad717",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT \"language\", \n",
    "    SUM(CAST(voted_up as int)) / CAST(COUNT(voted_up) as float) as ratio_positive_votes\n",
    "    FROM Nessie.steam.languages \n",
    "    GROUP BY \"language\"\n",
    "    ORDER BY 2 DESC\n",
    "    \"\"\"\n",
    "pl.read_database(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e1249-f7a6-4315-a3dd-9cfe1205c421",
   "metadata": {},
   "source": [
    "## Write\n",
    "In this example, we have our raw extract data in the Extract source - a CSV file for each game. Let's prepare a staging table for the CSV files, as they have a slightly different format than our final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72797c06-46f8-4d02-bd6c-0ea8d01396bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"\"\" \n",
    "    CREATE TABLE IF NOT EXISTS Nessie.steam.staging.languages (\n",
    "        game_id varchar(50),\n",
    "        recommendationid int,\n",
    "        \"language\" varchar(20),\n",
    "        timestamp_created int,\n",
    "        voted_up boolean\n",
    "    )\n",
    "    \"\"\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d7a78-5031-40eb-971b-d01f04b5eba3",
   "metadata": {},
   "source": [
    "In the Write stage, we start by creating a new branch where we can stage all our data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe6174-1c4d-4d37-b1ce-dce1cc604b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"CREATE BRANCH insert_demo AT BRANCH main IN Nessie\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdcaf65-854a-4d4d-9a83-899ce3e7838a",
   "metadata": {},
   "source": [
    "Now we can `COPY INTO` our staging table from our Extract file source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43410294-3db1-4b52-afdd-8ed033e8ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"\"\"\n",
    "    COPY INTO Nessie.steam.staging.languages \n",
    "    AT BRANCH insert_demo\n",
    "    FROM '@Extract/extract/reviews/550.csv'\n",
    "    ( EXTRACT_HEADER true, TRIM_SPACE true )\n",
    "    \"\"\")\n",
    "    print(f\"Inserted {c.fetchone()[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99818295-8698-41ef-80ae-f9d8cfc30bd7",
   "metadata": {},
   "source": [
    "We can verify that the main branch doesn't see any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f211c0-0ec5-4b33-8567-4b1cc1bc0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT * FROM Nessie.steam.staging.languages\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e1a27-7636-4b5e-a3f7-e44357a92cb1",
   "metadata": {},
   "source": [
    "While the `insert_demo` branch does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2c92e-cad4-40b3-a373-e13f7e93163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT * FROM Nessie.steam.staging.languages AT BRANCH insert_demo\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ba22d7-5e03-44e2-ba5f-dd1f07c4ea38",
   "metadata": {},
   "source": [
    "Since the `game_id` is stored in the file name instead of the data itself, we need to update our staged data with the game id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d32ed-ccc2-4a03-99c6-20a20c13f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"USE BRANCH insert_demo IN Nessie;\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706ca21-594b-466e-b594-d64836b05ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"UPDATE Nessie.steam.staging.languages AT BRANCH insert_demo SET game_id = '550' where game_id is null\")\n",
    "    print(f\"Inserted {c.fetchone()[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4c219-0597-4250-8be1-341561bfd9a8",
   "metadata": {},
   "source": [
    "Still no rows in the main branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5519a6-2ccd-4b32-975f-072e63775b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Branch main\")\n",
    "print(pl.read_database(\"SELECT * FROM Nessie.steam.staging.languages AT BRANCH main WHERE game_id = '550'\", conn))\n",
    "print(\"Branch insert_demo\")\n",
    "print(pl.read_database(\"SELECT * FROM Nessie.steam.staging.languages AT BRANCH insert_demo WHERE game_id = '550'\", conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785d8d1-f04a-448c-b08f-f58e94fa33e2",
   "metadata": {},
   "source": [
    "To finish our Write phase, we can move the staging data into the `languages` table with the correct conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9146c4-1307-4a82-a50b-70e33baacceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"\"\"\n",
    "    INSERT INTO Nessie.steam.languages AT BRANCH insert_demo \n",
    "    SELECT \n",
    "        game_id,\n",
    "        recommendationid,\n",
    "        \"language\",\n",
    "        to_timestamp(timestamp_created) as timestamp_created, \n",
    "        voted_up\n",
    "    FROM Nessie.steam.staging.languages AT BRANCH insert_demo\n",
    "    \"\"\")\n",
    "    print(f\"Inserted {c.fetchone()[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1578d05-d025-4ae9-bb55-aee5e0c0aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) as num_rows FROM Nessie.steam.languages AT BRANCH insert_demo\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe5a73-7fab-4f42-b059-0cfc09b2e6d4",
   "metadata": {},
   "source": [
    "Now we can run our Audit step - verifying data to ensure the data quality before consumers get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc3c7c-2fdc-4ef2-a259-38f6b7f6bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "     WITH num_reviews as (\n",
    "        select game_id, count(*) as num_reviews\n",
    "        FROM Nessie.steam.languages\n",
    "        GROUP BY game_id\n",
    "    ), num_language_reviews as (\n",
    "        SELECT game_id, \"language\", COUNT(*) as num_language_reviews\n",
    "        FROM Nessie.steam.languages l\n",
    "        GROUP BY game_id, \"language\"\n",
    "    )\n",
    "    SELECT l.game_id, l.\"language\",  num_language_reviews / cast(num_reviews as float) as language_ratio\n",
    "    FROM num_reviews r join num_language_reviews as l on r.game_id = l.game_id\n",
    "    \"\"\"\n",
    "\n",
    "ratio_df = pl.read_database(sql, conn)\n",
    "ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ede77-3f00-454f-8892-5b8cf63b19fc",
   "metadata": {},
   "source": [
    "We can perform sanity checks, such as checking that there aren't less than 15% of the reviews in english, or compare data across branches to make sure the difference is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234d4f1-9cc8-4ee8-b607-d8abd7f23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ratio_df.filter((pl.col('language') == 'english') & (pl.col('language_ratio') < 0.15)).is_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406acce-2b0b-48e3-b259-7135f07dd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pl.read_database(\"\"\"\n",
    "SELECT (SELECT COUNT(*) from Nessie.steam.languages AT BRANCH insert_demo) \n",
    "     - (SELECT COUNT(*) From Nessie.steam.languages AT BRANCH main)\n",
    "\"\"\", conn).item() == 858570"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdedecb3-8768-4195-b5cc-6643e5921d98",
   "metadata": {},
   "source": [
    "Given that we're happy with the new data - it passes all our data quality checks - we're ready for the Publish step. \n",
    "\n",
    "In a git-like fashion, we can merge the two branches and all our changes will be visible to the \"regular\" users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05a189-5f1b-4e3a-837a-09a359ced4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"MERGE BRANCH insert_demo into main in Nessie\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6e695-9355-42ef-922e-cfe83e4bcf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) as num_reviews FROM Nessie.steam.languages at branch main\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d5ce3-a37b-485e-9774-72b9cf3c5728",
   "metadata": {},
   "source": [
    "The changes have been merged in, and we can clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099224ae-f35d-4075-b0ab-c8c493c9a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"USE BRANCH main in Nessie\")\n",
    "    print(c.fetchone()[1])\n",
    "    c.execute(\"DROP BRANCH insert_demo in Nessie\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb848aa-f55d-4fcd-b5ba-d2f2cdf85395",
   "metadata": {},
   "source": [
    "# Time Travel\n",
    "\n",
    "Not only can we do Git branching, we can also do timetravel as part of the Iceberg spec. \n",
    "\n",
    "We could imagine that after the insert, we want to store a pointer to this version of the data, so we can go back to how data looked at an exact point in time. Iceberg has been keeping snapshots of each of our operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa388532-29b5-4a76-8c6d-5682e3f4130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT * FROM TABLE(table_snapshot('Nessie.steam.languages'))\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611484f8-cdd1-4307-a615-d4a65427c158",
   "metadata": {},
   "source": [
    "I can choose between a snapshot_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9eecd-15b8-4908-b02e-8cba9b4dcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) FROM Nessie.steam.languages at snapshot '3558310252565355831'\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa97ad1-c74b-43f8-86de-3a4b79a88853",
   "metadata": {},
   "source": [
    "Or a timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0f657-368a-4564-a1f4-e4e2ed2d0072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) FROM Nessie.steam.languages at TIMESTAMP '2024-12-01 21:25:00'\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37f5d68-0402-4599-a013-6e21ffd6045b",
   "metadata": {},
   "source": [
    "After publishing, we may want to store a tag on the data in order to be able to audit how the data looked at a specific point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9fd09-b7ad-403f-836a-ae0da63ee088",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute('CREATE TAG my_report FROM BRANCH main IN Nessie')\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ca4b5-49d5-4665-90bc-9b8cb7659c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"DELETE FROM Nessie.steam.languages where game_id = '550'\")\n",
    "    print(f\"Deleted {c.fetchone()[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c213d2e-c6c5-4752-a362-07125c0e6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) as num_rows FROM Nessie.steam.languages\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736a326-5d85-4e64-a2dd-6a3be53d9944",
   "metadata": {},
   "source": [
    "Oops! Good thing I have a tag - my report is unaffected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3693b3-2406-4559-bbb0-089e3d04a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) as num_rows FROM Nessie.steam.languages AT TAG my_report\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945c850-4a4a-429d-b1f0-1d84492de658",
   "metadata": {},
   "source": [
    "Let's rollback the accidental deletion by going for a snapshot before the accidental deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e7fde-9601-4663-b054-ee3af43e65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT * FROM TABLE(table_snapshot('Nessie.steam.languages'))\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085980c-5e5f-41c4-9ef0-8d679af9a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"ROLLBACK TABLE Nessie.steam.languages TO SNAPSHOT '7086946646526996956'\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd248a3-d5ef-4450-84d7-b71766d3ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) as num_rows FROM Nessie.steam.languages\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492a392-3d72-41b3-a70d-bbb4eb638970",
   "metadata": {},
   "source": [
    "Back to normal! Time to clean up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e31cb42-82c0-44ff-a2dc-1c082b89e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(\"DROP TABLE Nessie.steam.languages\")\n",
    "    print(c.fetchone()[1])\n",
    "    c.execute(\"DROP TABLE Nessie.steam.staging.languages\")\n",
    "    print(c.fetchone()[1])\n",
    "    c.execute(\"DROP TAG my_report IN Nessie\")\n",
    "    print(c.fetchone()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f32da-cdc6-458c-b456-651c5b3061ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
