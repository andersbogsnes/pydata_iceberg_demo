{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dddb10e6-4a25-46f9-8654-00c716a330f0",
   "metadata": {},
   "source": [
    "# Moving to Serverless AWS\n",
    "\n",
    "Iceberg has been adopted by all the major cloud providers in some shape or form, but AWS is certainly a big backer.\n",
    "\n",
    "The advantage of a big backer like AWS is that many of the serverless options in AWS already support Iceberg out of the box. AWS offers Athena, based on the Trino open-source project, as well as an Iceberg catalogue in AWS Glue. We can use `pyathena` to connect to Athena from Python to execute our SQL queries.\n",
    "\n",
    "You'll need to have completed the Terraform setup, and have set the `.env` variables to be able to follow along. There will also be some costs involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2242f2-b5d6-41bb-bc13-79df1d7b412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from pyathena import connect\n",
    "from pyathena.arrow.cursor import ArrowCursor\n",
    "import polars as pl\n",
    "from pyiceberg.catalog import load_catalog\n",
    "pl.Config().set_thousands_separator(',');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbfc72-213e-4574-bc42-dd915b11d3e4",
   "metadata": {},
   "source": [
    "When we connect to Athena, we need to specify where Athena should write out the results. Athena will always write out the results to a CSV file in the `s3_staging_dir` and then Pyathena will read the output csv and return the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65cf79-9f61-465b-821b-9d86746c83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect(s3_staging_dir=\"s3://pydata-copenhagen-datalake/athena\", region_name=\"eu-north-1\", cursor=ArrowCursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b76d41-4554-483c-8c7a-309a6f914cb5",
   "metadata": {},
   "source": [
    "Since Athena is basically serverless Trino, so we can also use it to create an Iceberg table, using the Trino connector for Iceberg.\n",
    "\n",
    "Note that part of the setup we've done is to upload all the CSVs to S3 and run a `Glue crawler` over the CSV bucket. This registers the CSV files as a table in the Glue Catalog, which is the metadata Athena needs to be able to execute its queries. Here we want to create an Iceberg table from the pile of CSV files, while also cleaning up the data a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70737e51-b012-47f2-bb0b-a987fc4b9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = r\"\"\" \n",
    "CREATE TABLE IF NOT EXISTS steam.reviews WITH (table_type = 'ICEBERG', location = 's3://pydata-copenhagen-datalake/staging/reviews', is_external = false) AS \n",
    "\n",
    "SELECT\n",
    "regexp_extract(\"$path\", 's3://pydata-copenhagen-datalake/extract/reviews/(\\w+).csv', 1) as game_id,\n",
    "recommendationid, \n",
    "language, \n",
    "--compatibility with Trino timestamps\n",
    "CAST(from_unixtime(timestamp_created) as timestamp(6)) as timestamp_created, \n",
    "CAST(from_unixtime(timestamp_updated) as timestamp(6)) as timestamp_updated,\n",
    "CAST(voted_up as boolean) as voted_up,\n",
    "votes_up,\n",
    "votes_funny,\n",
    "weighted_vote_score,\n",
    "comment_count,\n",
    "CAST(steam_purchase as boolean) as steam_purchase,\n",
    "CAST(received_for_free as boolean) as received_for_free,\n",
    "CAST(written_during_early_access as boolean) as written_during_early_access,\n",
    "CAST(hidden_in_steam_china as boolean) as hidden_in_steam_china,\n",
    "author_steamid,\n",
    "author_num_games_owned,\n",
    "author_num_reviews,\n",
    "author_playtime_forever,\n",
    "author_playtime_last_two_weeks,\n",
    "author_playtime_at_review,\n",
    "CAST(from_unixtime(author_last_played) as timestamp(6)) as author_last_played\n",
    "FROM reviews.reviews\n",
    "WHERE recommendationid is not null\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d72ff-0d72-4a10-8fcd-1d45ae385735",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as c:\n",
    "    c.execute(sql)\n",
    "    print(c.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e662e4e-aac2-4652-aa02-f6ecd38484c4",
   "metadata": {},
   "source": [
    "We can verify the count in the new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aec5b2-50e7-4a99-b4bb-0848f0e6dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.read_database(\"SELECT COUNT(*) as num_rows FROM steam.reviews\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492c25b-1a5f-4cc3-b871-fb28579af63d",
   "metadata": {},
   "source": [
    "Now the table is ready for analysis - how about calculating the most reviewed game per language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47da91-fe07-4509-bb84-cbb45817f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "with lang_reviews as (\n",
    "    SELECT language, game_id, count(*) as num_reviews \n",
    "    FROM steam.reviews group by language, game_id\n",
    "), max_reviews as (\n",
    "    select \n",
    "    language, \n",
    "    game_id, \n",
    "    num_reviews,\n",
    "    RANK() OVER (partition by language order by num_reviews desc) as ordering \n",
    "    from lang_reviews\n",
    ")\n",
    "select language, game_id, num_reviews from max_reviews\n",
    "where ordering = 1\n",
    "order by num_reviews desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e73c7-05a7-4472-a584-34c88d12c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_reviewed_df = pl.read_database(sql, conn)\n",
    "most_reviewed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8d262-7ef1-48f4-befb-996427dafb3c",
   "metadata": {},
   "source": [
    "Because this is still Iceberg, we can use `pyiceberg` to talk to the AWS Glue catalog as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da4676-4711-48ac-bc4b-60a584c38a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = load_catalog(\"aws_iceberg\", **{\"type\": \"glue\", \"glue.region\": \"eu-north-1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cd652-cdaa-4cab-b660-0d259434bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad72c5-acba-4dd7-a81f-54c42651f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.list_tables(\"steam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72440559-7f93-4c5d-b47f-8bea48b5c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.load_table(\"steam.reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef72d3-bd3e-4c2e-9614-7d3bf62e114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.from_arrow(table.scan(selected_fields=['game_id', 'language', 'voted_up'], row_filter=\"game_id == '550'\").to_arrow())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23b6f3-7c56-4c01-bf95-dd4d5ee2f698",
   "metadata": {},
   "source": [
    "We can even use polars directly to query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd54b3-6c57-4c94-8a19-c6e583318c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.scan_iceberg(table).select(\"game_id\", \"language\").filter(pl.col(\"game_id\") == '550').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812aa837-ec3a-4fc5-ab95-c32c853f0069",
   "metadata": {},
   "source": [
    "This interopability is one of the key benefits of moving towards Iceberg as a storage layer. Athena costs 5\\$ per TB scanned - using `polars` costs me 0\\$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
